/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    ablab/hpcdockbench Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/
// -- * Automatic container definition
// -- * why? https://apptainer.org/docs/user/main/gpu.html
// Detect host glibc version from wrapper (fallback = 2.31)
def glibc = System.getenv('NXF_GLIBC_VERSION') ?: '2.31'

def pickContainerGPU(glibc) {
    def containerCandidates = [
        '2.27': 'docker.io/hgrabski/hpc_dock_bench:gpu-18.04',
        '2.31': 'docker.io/hgrabski/hpc_dock_bench:gpu-20.04',
        '2.35': 'docker.io/hgrabski/hpc_dock_bench:gpu-22.04',
        '2.39': 'docker.io/hgrabski/hpc_dock_bench:gpu-24.04'
    ]

    def v = new BigDecimal(glibc)
    if (v >= 2.39) return containerCandidates['2.39']
    if (v >= 2.35) return containerCandidates['2.35']
    if (v >= 2.31) return containerCandidates['2.31']
    return containerCandidates['2.27']
}

def pickContainerCPU(glibc) {
    def containerCandidates = [
        '2.27': 'docker.io/hgrabski/hpc_dock_bench:cpu-18.04',
        '2.31': 'docker.io/hgrabski/hpc_dock_bench:cpu-20.04',
        '2.35': 'docker.io/hgrabski/hpc_dock_bench:cpu-22.04',
        '2.39': 'docker.io/hgrabski/hpc_dock_bench:cpu-24.04'
    ]

    def v = new BigDecimal(glibc)
    if (v >= 2.39) return containerCandidates['2.39']
    if (v >= 2.35) return containerCandidates['2.35']
    if (v >= 2.31) return containerCandidates['2.31']
    return containerCandidates['2.27']
}

// Global default params, used in configs
params {


    // -- workDir can be customized
    //-- ! This makes sure that $HOME folder is not being used, and Expanse users won't be angry at you.
    //output_workdir = null

    // Change custom workDir
    //workDir = "${params.output_workdir ?: 'work' }"
    workDir = null


    // Input options
    input                      = null

    // Boilerplate options
    outdir                       = null
    publish_dir_mode             = 'copy'
    email                        = null
    email_on_fail                = null
    plaintext_email              = false
    monochrome_log               = false
    monochrome_logs              = false
    hook_url                     = System.getenv('HOOK_URL')
    help                         = false
    help_full                    = false
    show_hidden                  = false
    version                      = false
    pipelines_testdata_base_path = 'https://raw.githubusercontent.com/nf-core/test-datasets/'
    trace_report_suffix          = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

    config_profile_name        = null
    config_profile_description = null

    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_contact     = null
    config_profile_url         = null

    // Schema validation default options
    validate_params            = true

    // -- * Singularity containers so it can use sif image from local storage
    useGPU = false
    singularity_pull_docker_container = true
    singularity_use_local_file = false
    singularity_local_cpu_container = null

    singularity_local_gpu_container = null

    // -- * Settings to save intermediate results
    save_intermediate = false

    // -- * ICM default arguments, to match journal change effort to 32 and conformations to 40
    effort = 5.0
    conformations = 10
    random_seed = 25051990

    icm_home = null




    benchmark_dataset = "https://zenodo.org/records/8278563/files/posebusters_paper_data.zip"
    benchmark_pb_correction = "https://github.com/maabuu/posebusters/files/14516485/posebusters_pdb_ccd_ids.txt"


    // container_gpu_link = 'docker.io/hgrabski/hpc_dock_bench:gpu'


    // -- * Mount options, very important when using containers and network attached storage
    mount_options = null

    smart_container = true

    // -- * Default image containers from DockerHub, will use the same image for both CPU and GPU version
    container_gpu_link= params.smart_container ? pickContainerGPU(glibc) : 'docker.io/hgrabski/hpc_dock_bench:gpu-22.04'
    container_cpu_link= params.smart_container ? pickContainerCPU(glibc) : 'docker.io/hgrabski/hpc_dock_bench:cpu-22.04'

    // -- * project name for SLURM based HPC cluster
    project = null

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

profiles {
    debug {
        dumpHashes              = true
        process.beforeScript    = 'echo $HOSTNAME'
        cleanup                 = false
        nextflow.enable.configProcessNamesValidation = true
    }
    conda {
        conda.enabled           = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        conda.channels          = ['conda-forge', 'bioconda']
        apptainer.enabled       = false
    }
    mamba {
        conda.enabled           = true
        conda.useMamba          = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        docker.runOptions       = '-u $(id -u):$(id -g) -v $HOME:$HOME --network host'
    }
    arm64 {
        process.arch            = 'arm64'
        // TODO https://github.com/nf-core/modules/issues/6694
        // For now if you're using arm64 you have to use wave for the sake of the maintainers
        // wave profile
        apptainer.ociAutoPull   = true
        singularity.ociAutoPull = true
        wave.enabled            = true
        wave.freeze             = true
        wave.strategy           = 'conda,container'
    }
    singularity {
        singularity.enabled     = true
        singularity.autoMounts  = true
        singularity.runOptions = "--bind $HOME:$HOME"
        conda.enabled           = false
        docker.enabled          = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    podman {
        podman.enabled          = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    shifter {
        shifter.enabled         = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    charliecloud {
        charliecloud.enabled    = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        apptainer.enabled       = false
    }
    apptainer {
        apptainer.enabled       = true
        apptainer.autoMounts    = true
        // -- * make mount home directory default
        apptainer.runOptions = "--bind  $HOME:$HOME"
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
    }
    wave {
        apptainer.ociAutoPull   = true
        singularity.ociAutoPull = true
        wave.enabled            = true
        wave.freeze             = true
        wave.strategy           = 'conda,container'
    }
    gpu {
        docker.runOptions       = '-u $(id -u):$(id -g) --gpus all'
        apptainer.runOptions    = '--nv'
        singularity.runOptions  = '--nv'
    }



    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }

    slurm { includeConfig 'conf/slurm.config' }
    expanse { includeConfig 'conf/expanse.config' }
    aznavour { includeConfig 'conf/aznavour.config' }
}



// Load nf-core custom profiles from different institutions
includeConfig params.custom_config_base && (!System.getenv('NXF_OFFLINE') || !params.custom_config_base.startsWith('http')) ? "${params.custom_config_base}/nfcore_custom.config" : "/dev/null"

// Load ablab/hpcdockbench custom profiles from different institutions.
// TODO nf-core: Optionally, you can add a pipeline-specific nf-core config at https://github.com/nf-core/configs
// includeConfig params.custom_config_base && (!System.getenv('NXF_OFFLINE') || !params.custom_config_base.startsWith('http')) ? "${params.custom_config_base}/pipeline/hpcdockbench.config" : "/dev/null"

// Set default registry for Apptainer, Docker, Podman, Charliecloud and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Charliecloud / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry    = 'quay.io'
docker.registry       = 'quay.io'
podman.registry       = 'quay.io'
singularity.registry  = 'quay.io'
charliecloud.registry = 'quay.io'



// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Set bash options
process.shell = [
    "bash",
    "-C",         // No clobber - prevent output redirection from overwriting files.
    "-e",         // Exit if a tool returns a non-zero status/exit code
    "-u",         // Treat unset variables and parameters as an error
    "-o",         // Returns the status of the last command to exit..
    "pipefail"    //   ..with a non-zero status or zero if all successfully execute
]

// Disable process selector warnings by default. Use debug profile to enable warnings.
nextflow.enable.configProcessNamesValidation = false

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${params.trace_report_suffix}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${params.trace_report_suffix}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${params.trace_report_suffix}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${params.trace_report_suffix}.html"
}

manifest {
    name            = 'ablab/hpcdockbench'
    author          = """Hovakim Grabski,Siranuysh Grabska,Ruben Abagyan""" // The author field is deprecated from Nextflow version 24.10.0, use contributors instead
    contributors    = [
        // TODO nf-core: Update the field with the details of the contributors to your pipeline. New with Nextflow version 24.10.0
        [
            name: 'Hovakim Grabski',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
        [
            name: 'Siranuysh Grabska',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
        [
            name: 'Ruben Abagyan',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
    ]
    homePage        = 'https://github.com/hovo1990/hpc_dock_bench'
    description     = """A bioinformatics pipeline to perform docking benchmark on Astex and PoseBusters data sets."""
    mainScript      = 'main.nf'
    defaultBranch   = 'master'
    nextflowVersion = '!>=25.04.2'
    version         = '1.0.0dev'
    doi             = ''
}

// Nextflow plugins
plugins {
    id 'nf-schema@2.5.1' // Validation of pipeline parameters and creation of an input channel from a sample sheet
}

validation {
    defaultIgnoreParams = ["genomes"]
    monochromeLogs = params.monochrome_log
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'
